"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö
"""
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import yaml

class DataLoader:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""

    def __init__(self, config_path):
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)

    def load_and_prepare_data(self):
        """–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
        print(f"üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞: {self.config['dataset']['name']}")

        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        raw_data = self._load_raw_data()

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        X, y, feature_names = self._prepare_features_and_target(raw_data)

        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        X_train, X_test, y_train, y_test, scaler = self._preprocess_data(X, y)

        return {
            'X_train': X_train,
            'X_test': X_test,
            'y_train': y_train,
            'y_test': y_test,
            'feature_names': feature_names,
            'scaler': scaler,
            'raw_data': raw_data
        }

    def _load_raw_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        dataset_config = self.config['dataset']
        special = dataset_config.get('special_preprocessing', {})

        if dataset_config['source_type'] == 'url':
            file_path = dataset_config['file_path']

            if special.get('type') == 'breast_cancer':
                # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è Breast Cancer (–±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤)
                column_names = special['column_names']
                data = pd.read_csv(file_path, header=None, names=column_names)
            else:
                # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å URL
                data = pd.read_csv(file_path)

        elif dataset_config['source_type'] == 'local':
            file_path = dataset_config['file_path']

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –µ—Å—Ç—å –ª–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏
            has_header = special.get('has_header', True)
            column_names = special.get('column_names')

            if file_path.endswith('.csv'):
                if has_header and not column_names:
                    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ –∏–∑ —Ñ–∞–π–ª–∞
                    data = pd.read_csv(file_path)
                elif not has_header and column_names:
                    # –ó–∞–≥—Ä—É–∑–∫–∞ –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–º–µ–Ω–∞–º–∏
                    data = pd.read_csv(file_path, header=None, names=column_names)
                else:
                    # Fallback - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
                    data = pd.read_csv(file_path)

            elif file_path.endswith(('.xlsx', '.xls')):
                if has_header and not column_names:
                    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ Excel —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
                    data = pd.read_excel(file_path)
                elif not has_header and column_names:
                    # –ó–∞–≥—Ä—É–∑–∫–∞ Excel –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–º–µ–Ω–∞–º–∏
                    data = pd.read_excel(file_path, header=None, names=column_names)
                else:
                    # Fallback - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ Excel
                    data = pd.read_excel(file_path)
            else:
                raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {file_path}")
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π source_type: {dataset_config['source_type']}")

        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {data.shape[0]} –æ–±—Ä–∞–∑—Ü–æ–≤, {data.shape[1]} –∫–æ–ª–æ–Ω–æ–∫")
        print(f"üìã –ö–æ–ª–æ–Ω–∫–∏: {list(data.columns)}")
        return data

    def _prepare_features_and_target(self, data):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ X, y –∏ –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        special = self.config['dataset'].get('special_preprocessing', {})
        dataset_type = special.get('type', 'standard')

        if dataset_type == 'breast_cancer':
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è Breast Cancer
            target_col = special['target_column']
            feature_start = special['feature_start_col']
            target_mapping = special['target_mapping']

            # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è —Å –º–∞–ø–ø–∏–Ω–≥–æ–º
            y = data[target_col].map(target_mapping)

            # –ü—Ä–∏–∑–Ω–∞–∫–∏ –Ω–∞—á–∏–Ω–∞—è —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏
            X = data.iloc[:, feature_start:].copy()
            feature_names = X.columns.tolist()

        elif dataset_type == 'heart_disease' or dataset_type == 'standard':
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è Heart Disease –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
            target_col = special.get('target_column', 'target')
            target_mapping = special.get('target_mapping')

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ target –∫–æ–ª–æ–Ω–∫–∞
            if target_col not in data.columns:
                # –ï—Å–ª–∏ target –∫–æ–ª–æ–Ω–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∫–æ–ª–æ–Ω–∫—É
                target_col = data.columns[-1]
                print(f"‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ '{special.get('target_column', 'target')}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è '{target_col}'")

            # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
            if target_mapping:
                y = data[target_col].map(target_mapping)
            else:
                y = data[target_col]

            # –ü—Ä–∏–∑–Ω–∞–∫–∏ - –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –∫—Ä–æ–º–µ target
            X = data.drop(columns=[target_col])
            feature_names = X.columns.tolist()

        else:
            # –ü–æ–ª–Ω–æ—Å—Ç—å—é —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            # –ò—â–µ–º target –∫–æ–ª–æ–Ω–∫—É –∏–ª–∏ –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é
            target_candidates = ['target', 'label', 'class', 'y', 'output']
            target_col = None

            for candidate in target_candidates:
                if candidate in data.columns:
                    target_col = candidate
                    break

            if target_col is None:
                target_col = data.columns[-1]
                print(f"‚ö†Ô∏è Target –∫–æ–ª–æ–Ω–∫–∞ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ—Å–ª–µ–¥–Ω—è—è –∫–æ–ª–æ–Ω–∫–∞: '{target_col}'")

            y = data[target_col]
            X = data.drop(columns=[target_col])
            feature_names = X.columns.tolist()

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–ª–∞—Å—Å–æ–≤
        self._print_class_distribution(y, target_col)

        print(f"üìä –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ:")
        print(f"   –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: '{target_col}' ({len(y.unique())} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π)")
        print(f"   –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(feature_names)}")
        print(f"   –ù–∞–∑–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {feature_names[:5]}{'...' if len(feature_names) > 5 else ''}")

        return X, y, feature_names

    def _preprocess_data(self, X, y):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        prep_config = self.config['preprocessing']

        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
        if prep_config['scaling']:
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
        else:
            X_scaled = X.values
            scaler = None

        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
        stratify = y if prep_config['stratify'] else None

        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y,
            test_size=prep_config['test_size'],
            random_state=prep_config['random_state'],
            stratify=stratify
        )

        print(f"‚úÖ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
        print(f"   Train: {X_train.shape[0]} –æ–±—ä–µ–∫—Ç–æ–≤")
        print(f"   Test: {X_test.shape} –æ–±—ä–µ–∫—Ç–æ–≤")
        print(f"   –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {X_train.shape[1]}")

        return X_train, X_test, y_train, y_test, scaler

    def _print_class_distribution(self, y, target_col):
        """–í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–ª–∞—Å—Å–æ–≤"""
        print(f"\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è '{target_col}':")
        for class_val in sorted(y.unique()):
            count = (y == class_val).sum()
            percentage = count / len(y) * 100
            print(f"   –ö–ª–∞—Å—Å {class_val}: {count} –æ–±—Ä–∞–∑—Ü–æ–≤ ({percentage:.1f}%)")
